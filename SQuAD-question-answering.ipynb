{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2940905c-48ec-4810-8e19-7b7ac33e2bda",
   "metadata": {},
   "source": [
    "# SQuAD Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b0eef-83bc-4ba5-ab39-7a73c11bacbc",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab54ce-bf7a-4824-a4da-5b03d30ace70",
   "metadata": {},
   "source": [
    "Welcome to the \"Enhancing Question Answering with Transformer Models\" project! In this endeavor, I will be delving into the realm of Natural Language Processing to tackle the challenging task of building a model that can accurately comprehend and answer questions based on given contexts. By harnessing the transformative capabilities of Transformer architectures, I aim to create a robust system that not only understands the nuances of human language but also delivers contextually relevant answers.\n",
    "\n",
    "The heart of our project beats with the transformative potential of Transformer architecture, a groundbreaking innovation that has revolutionized the field of NLP. Inspired by the \"Attention is All You Need\" paper, we will harness the capabilities of self-attention mechanisms, multi-head attention, and feedforward neural networks to build models that can efficiently capture intricate linguistic relationships, even in lengthy and complex text.\n",
    "\n",
    "As I progress through this project, I'll explore data preprocessing, model selection, fine-tuning, and evaluation methodologies, aiming to equip the model with the ability to interpret context and contextually generate insightful answers. Whether it's tackling questions on passages of text, summarizing content, or generating human-like responses, this project is a tribute to the power of modern AI in understanding and manipulating language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f3fe9-aaf5-4333-897b-2081cca7124d",
   "metadata": {},
   "source": [
    "## 2 Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc1d32-d32c-4f31-ae8e-a84b6841ebe2",
   "metadata": {},
   "source": [
    "### 2.1 Packages Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93074cd-3727-4e2a-9432-fca4eb79339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.1\n",
      "torchvision version: 0.15.2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    from transformers import pipeline\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    !pip install torch torchvision\n",
    "    !pip install transformers\n",
    "    import torch\n",
    "    import torchvision\n",
    "    from transformers import pipeline\n",
    "    print(f\"torch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e904b2a-fcc1-4f45-a1cb-83ea99ed55ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598050713539124},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b7c19-b58f-415c-83e0-d01408b8b6a0",
   "metadata": {},
   "source": [
    "### 2.2 Acquiring The SQuAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf2793c-bf30-4ae6-a80c-57c9cd05d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from datasets import load_dataset\n",
    "    raw_datasets = load_dataset(\"squad\")\n",
    "except:\n",
    "    !pip install datasets\n",
    "    from datasets import load_dataset\n",
    "    raw_datasets = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e1daae-2915-481d-b9fd-901bcdffc562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531194cb-834e-41f6-acf0-451852090d12",
   "metadata": {},
   "source": [
    "## 3 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f9ae29-0991-47b5-a8ec-83a9f6d8b0d2",
   "metadata": {},
   "source": [
    "Data exploration is a crucial step that allows us to understand the nuances and characteristics of the dataset, enabling us to make informed decisions during preprocessing and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62815b-5d5b-40a2-bb2e-ba85a93c1e39",
   "metadata": {},
   "source": [
    "### 3.1 Basic Statistics\n",
    "To perform data exploration on the SQuAD dataset, we're following a systematic process. We're starting by calculating basic statistics such as the number of examples in the dataset, the average length of questions and contexts, and the distribution of answer lengths. These statistics give us a high-level overview of the dataset's composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43e0151-e626-4015-a9a5-204f4e9e2b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 87599\n",
      "Average context length: 754.36\n",
      "Average question length: 59.57\n",
      "Average answer length: 20.15\n"
     ]
    }
   ],
   "source": [
    "# Access the training split\n",
    "train_data = raw_datasets[\"train\"]\n",
    "\n",
    "# Basic statistics\n",
    "num_examples = len(train_data)\n",
    "context_lengths = [len(example[\"context\"]) for example in train_data]\n",
    "question_lengths = [len(example[\"question\"]) for example in train_data]\n",
    "answer_lengths = [len(example[\"answers\"][\"text\"][0]) for example in train_data]\n",
    "\n",
    "avg_context_length = sum(context_lengths) / num_examples\n",
    "avg_question_length = sum(question_lengths) / num_examples\n",
    "avg_answer_length = sum(answer_lengths) / num_examples\n",
    "\n",
    "print(f\"Number of examples: {num_examples}\")\n",
    "print(f\"Average context length: {avg_context_length:.2f}\")\n",
    "print(f\"Average question length: {avg_question_length:.2f}\")\n",
    "print(f\"Average answer length: {avg_answer_length:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb8c5b-8fed-495c-91c6-242a16cca586",
   "metadata": {},
   "source": [
    "### 3.2 Sample Viewing\n",
    "Next, we're randomly sampling examples from the dataset and visually inspecting them. This hands-on approach helps us grasp the format of questions, contexts, and answer spans. We're also using visualizations such as histograms and box plots to analyze the distribution of question and context lengths, aiding in identifying potential outliers or patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "583a045c-0068-416f-a9f1-7e96ea8fb868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary. \n",
      "\n",
      "Question:  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? \n",
      "\n",
      "Answer:  {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Context: \", train_data[0][\"context\"], \"\\n\")\n",
    "print(\"Question: \", train_data[0][\"question\"], \"\\n\")\n",
    "print(\"Answer: \", train_data[0][\"answers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e97a562-c5dd-41a3-ae82-64db4fff1375",
   "metadata": {},
   "source": [
    "### 3.3 Answer Types and Categories\n",
    "Finally, we will be exploring the different types of answers present in the dataset (e.g., named entities, numeric answers, descriptive answers). This information can guide our preprocessing and model design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957634bb-159b-42e0-abbd-cbf240b312ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Answers: 6912\n",
      "Named Entities: 1225\n",
      "Descriptive Answers: 56857\n",
      "Other Answers: 22605\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression patterns to identify answer types\n",
    "numeric_pattern = re.compile(r'^\\d+(\\.\\d+)?$')\n",
    "\n",
    "# Initialize counters for different answer types\n",
    "numeric_answers = 0\n",
    "named_entities = 0\n",
    "descriptive_answers = 0\n",
    "other_answers = 0\n",
    "\n",
    "# Loop through examples to categorize answers\n",
    "for example in train_data:\n",
    "    answer_text = example[\"answers\"][\"text\"][0]\n",
    "    \n",
    "    if re.match(numeric_pattern, answer_text):\n",
    "        numeric_answers += 1\n",
    "    elif answer_text.isupper():\n",
    "        named_entities += 1\n",
    "    elif len(answer_text.split()) > 1:\n",
    "        descriptive_answers += 1\n",
    "    else:\n",
    "        other_answers += 1\n",
    "\n",
    "# Print the counts for different answer types\n",
    "print(f\"Numeric Answers: {numeric_answers}\")\n",
    "print(f\"Named Entities: {named_entities}\")\n",
    "print(f\"Descriptive Answers: {descriptive_answers}\")\n",
    "print(f\"Other Answers: {other_answers}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8c6d2-23c8-4e7c-914a-7a617661bba9",
   "metadata": {},
   "source": [
    "## 4 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f84b693-6822-46a6-b18d-b95117fa401e",
   "metadata": {},
   "source": [
    "Data preprocessing plays a pivotal role in our project focused on enhancing question answering using Transformer-based models. It serves as the foundation that empowers these advanced models to understand and interpret human language effectively. By transforming raw text into a structured format, we enable the models to process, learn from, and generate accurate responses based on the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb1f87-c3c5-43bf-9163-a732935dad09",
   "metadata": {},
   "source": [
    "### 4.1 Tokenization\n",
    "Transformers operate at the token level, and each token typically corresponds to a word or subword unit. Preprocessing involves tokenizing the text into these units, allowing the model to understand and process the input. Tokenization is a fundamental step in preparing text data for Transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48bc402-933f-4f2c-823c-06637534b4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] architecturally, the school has a catholic character. atop the main building\\'s gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Sample text for tokenization\n",
    "context = train_data[0][\"context\"]\n",
    "question = train_data[0][\"question\"]\n",
    "tokenized_data = tokenizer(context, question)\n",
    "\n",
    "# Print the first tokenized example\n",
    "tokenizer.decode(tokenized_data[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14e5c1-7bd8-405d-9c66-14f70a4c40d2",
   "metadata": {},
   "source": [
    "### 4.2 Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c122d-972b-4144-b894-03b5ac4e4fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "749258cd-3569-4238-9833-376ddc40b63e",
   "metadata": {},
   "source": [
    "### 4.3 Positional Encodings\n",
    "Transformers do not inherently understand the position of words in a sequence. Preprocessing involves adding positional encodings to the tokenized sequences, providing information about the order of tokens. This enables the model to consider the sequential nature of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc4df1-ece4-4ffb-abb3-2124b98e3dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb88d1a5-afb8-47af-842c-40265a178e2b",
   "metadata": {},
   "source": [
    "### 4.4 Target Labels\n",
    "For tasks like question answering, preprocessing is essential for creating target labels that indicate the start and end positions of answer spans within the context. This step is crucial for training the model to predict answer spans accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19bb90-7c27-4ebe-bbf9-d337625a9e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37ef6c43-685e-4287-af12-15c3b64270a0",
   "metadata": {},
   "source": [
    "### 4.5 Handling Special Tokens\n",
    "Transformers use special tokens (e.g., [CLS], [SEP]) to indicate the beginning and separation of sequences. Preprocessing involves adding these tokens appropriately to the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfcf5e1-6f6d-4081-873f-77f70eec2344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "851b5d2a-c93b-4a3a-9201-9f270305e42a",
   "metadata": {},
   "source": [
    "### 4.6 Data Splitting\n",
    "Preprocessing includes splitting the dataset into training, validation, and test sets. This step is crucial for proper model evaluation and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75624d42-a5b4-46e5-8999-9f15e93afaac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0957b093-0623-413e-848c-23be48623465",
   "metadata": {},
   "source": [
    "## 5 Designing a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1616da8-c2ce-43e3-ac94-d8def8719738",
   "metadata": {},
   "source": [
    "### 5.1 Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67435db5-b627-46b0-abb7-21a55daabf7a",
   "metadata": {},
   "source": [
    "### 5.2 Model Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aaabbf-efdf-41fa-97ed-718ccf740991",
   "metadata": {},
   "source": [
    "### 5.3 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b649d1-48a8-46e8-af66-602c0a0a5d27",
   "metadata": {},
   "source": [
    "### 5.4 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb71ed-53a2-41eb-935e-bd982804621f",
   "metadata": {},
   "source": [
    "## 6 Implementing Transformer-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374831b6-1776-4fe4-8b9e-82e9025358b1",
   "metadata": {},
   "source": [
    "## 7 Using the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d36a5-9708-400c-8c16-545ae6550877",
   "metadata": {},
   "source": [
    "## 8 Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
